
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

class ChatbotPhongChongLuaDao:
    def __init__(self):
        from fraud_rules import fraud_rules
        from train_data_augmented import X_train, y_train
        self.fraud_rules = fraud_rules
        self.X_train = X_train
        self.y_train = y_train

        self.classifier = Pipeline([
            ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), strip_accents='unicode')),
            ('classifier', MultinomialNB())
        ])
        self.classifier.fit(self.X_train, self.y_train)

        self.fuzzy_risk_levels = {
            'low': lambda x: max(0, min(1, (0.4 - x) / 0.4)) if x <= 0.4 else 0,
            'medium': lambda x: max(0, min((x - 0.2) / 0.3, (0.7 - x) / 0.3)) if 0.2 <= x <= 0.7 else 0,
            'high': lambda x: max(0, min(1, (x - 0.5) / 0.5)) if x >= 0.5 else 0
        }

    def normalize_text(self, text):
        text = text.lower()
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def map_label_to_text(self, label):
        mapping = {
            'trung_thuong': 'L·ª´a ƒë·∫£o tr√∫ng th∆∞·ªüng',
            'phishing': 'L·ª´a ƒë·∫£o gi·∫£ m·∫°o (Phishing)',
            'dau_tu': 'L·ª´a ƒë·∫£o ƒë·∫ßu t∆∞',
            'tai_chinh': 'L·ª´a ƒë·∫£o t√†i ch√≠nh',
            'mua_sam': 'L·ª´a ƒë·∫£o mua s·∫Øm',
            'viec_lam': 'L·ª´a ƒë·∫£o vi·ªác l√†m',
            'ho_tro': 'L·ª´a ƒë·∫£o h·ªó tr·ª£ k·ªπ thu·∫≠t',
            'gia_mao_nguoi_than': 'L·ª´a ƒë·∫£o gi·∫£ m·∫°o ng∆∞·ªùi th√¢n',
            'tin_dung': 'L·ª´a ƒë·∫£o t√≠n d·ª•ng',
            'hop_le': 'N·ªôi dung b√¨nh th∆∞·ªùng kh√¥ng c√≥ d·∫•u hi·ªáu l·ª´a ƒë·∫£o'
        }
        return mapping.get(label, label)

    def fuzzy_risk_evaluation(self, probability):
        membership_values = {level: func(probability) for level, func in self.fuzzy_risk_levels.items()}
        max_level = max(membership_values.items(), key=lambda x: x[1])
        return max_level[0] if max_level[1] > 0 else "kh√¥ng x√°c ƒë·ªãnh"

    def rule_based_detection(self, text):
        cleaned = self.normalize_text(text)
        matched_rules = []
        for rule in self.fraud_rules:
            if 'pattern' in rule and re.search(rule['pattern'], cleaned):
                matched_rules.append(rule)
            elif 'keywords' in rule and any(kw in cleaned for kw in rule['keywords']):
                matched_rules.append(rule)
        return matched_rules

    def bayes_detection_detail(self, text):
        proba = self.classifier.predict_proba([text])[0]
        labels = self.classifier.classes_
        return sorted(zip(labels, proba), key=lambda x: x[1], reverse=True)

    def respond(self, user_input):
        rules = self.rule_based_detection(user_input)
        bayes_results = self.bayes_detection_detail(user_input)
        top_label, top_prob = bayes_results[0]
        risk_level = self.fuzzy_risk_evaluation(top_prob)

        response = []
        response.append("üõ°Ô∏è========== K·∫æT QU·∫¢ PH√ÇN T√çCH ==========üõ°Ô∏è")

        if rules:
            response.append("üìè [Ph√°t hi·ªán theo lu·∫≠t]")

            # S·∫Øp x·∫øp t·∫•t c·∫£ lu·∫≠t theo ƒë·ªô tin c·∫≠y gi·∫£m d·∫ßn
            sorted_rules = sorted(rules, key=lambda r: r['confidence'], reverse=True)

            # Duy·ªát v√† ch·ªçn t·ªëi ƒëa 3 lo·∫°i kh√°c nhau
            seen_types = set()
            unique_rules = []
            for rule in sorted_rules:
                if rule['fraud_type'] not in seen_types:
                    unique_rules.append(rule)
                    seen_types.add(rule['fraud_type'])
                if len(unique_rules) == 3:
                    break

            # In ra k·∫øt qu·∫£
            for rule in unique_rules:
                response.append(f"‚Ä¢ Lo·∫°i: {rule['fraud_type']}")
                response.append(f"  ‚û§ Khuy·∫øn ngh·ªã: {rule['advice']}")
            response.append("")

        # Ph√¢n t√≠ch m√¥ h√¨nh
        response.append("üß† [Ph√¢n t√≠ch t·ª´ m√¥ h√¨nh h·ªçc m√°y]")
        for i, (label, prob) in enumerate(bayes_results[:5], 1):
            response.append(f"{i}. {self.map_label_to_text(label)} ‚Äî {prob*100:.2f}%")

        # M·ª©c r·ªßi ro t·ªïng th·ªÉ
        response.append("")
        response.append(f"üö® [M·ª©c ƒë·ªô r·ªßi ro t·ªïng th·ªÉ]: {risk_level.upper()}")

        # G·ª£i √Ω n·∫øu r·ªßi ro cao
        if top_label != "hop_le" and top_prob >= 0.6:
            response.append("")
            response.append("üí° [C·∫£nh b√°o]")
            response.append("N·ªôi dung c√≥ d·∫•u hi·ªáu R·ª¶I RO CAO.")
            response.append("‚ùó H√£y x√°c minh ngu·ªìn g·ªëc tr∆∞·ªõc khi cung c·∫•p th√¥ng tin ho·∫∑c chuy·ªÉn ti·ªÅn.")

        response.append("üõ°Ô∏è=======================================üõ°Ô∏è")
        return "\n".join(response)
